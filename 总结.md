## 1. 评测tof和realsense传感器在室外条件下的性能
- 背景  
由于扫地机业务使用的tof传感器评测都是在室内环境下，并且对测评报告没有很好的量化指标，因此通过此工作，确认和量化在割草机工作环境下，tof和realsense深度传感器的性能。
- 流程  
前往户外的草地，使用tof和realsense对大盆栽、小盆栽、桌子、地灯、柱子、景观石、栅栏、椅子和充电桩等几种草地常见障碍物，在不同光照条件下（正常阳光、逆光和背光），不同拍摄距离（0.5m、1m和2m）收集数据。  
采集完的数据，拆包转成depth image后，使用labelme进行障碍物标注，方便提取障碍物和其周围的深度信息。通过DBSCAN聚类方法，过滤深度点云的杂点，聚类障碍物表面点云。统计各类障碍物聚类点云的variance和distance。  
- 结论  
tof深度传感器对黑色物体和金属物体的测距会失效，realsense深度传感器没有失效场景。

## 2. 模型压缩调研
- 背景  
扫地机硬件设备限制其部署的模型大小和运算量，因此想通过模型压缩达到不失太多模型性能的情况下，达到模型大小和运算量的缩减。  
- 过程  
学习和调研几种模型压缩方法：模型量化、模型剪枝和知识蒸馏，着重复现知识蒸馏对于目标检测模型的SOTA论文。  
- 结果  
手动实现基于相应的知识蒸馏，通过使用L2 loss的响应蒸馏，对yolov5s进行知识蒸馏（教师模型是yolov5l），在coco数据集上验证其模型提升效果（mAp提升3.2%左右）  

## 3. 深度补全调研和验证
- 背景  
在割草机深度方案测试过程中 ，发现仅使用tof硬件传感器作为深度方案会有以下问题：
  1. tof深度传感器在部分室外特定场景无法work【黑色/金属】；
  2. tof深度传感器的分辨率较低；
  3. 需要提高tof深度传感器精度/效果等需求时，只能使用硬件更新的方式；
图像深度补全旨在高分辨率彩色图像的引导下，从稀疏深度图预测密集深度图。我们希望能在分辨率相差较大的tof和realsense传感器上，能够实现tof点映射后形成的稀疏深度图，对其进行深度补全。  
- 方案  
用性能较好的realsense深度传感器作为groundtruth，将PENet作为网络模型解决tof深度传感器在特定场景下的不足。  
- 硬件：
  1. 欧非tof深度传感器，分辨率240 x 140；
  2. realsense d435i深度传感器，分辨率640 x 480，具有rgb和深度传感器；
将tof和realsense固定在一个模组，进行相机标定和图像收集。  
- 流程：
  1. tof和realsense进行相机标定，输出标定参数；
  2. tof和realsense确定相交区域：[ (48, 9) , (170, 101) ]，约占tof像素的33%；
  3. 确定tof点映射到realsense上的选点方案；
  4. 自采数据集的制作（rgb、depth、mapping depth）；
  5. 利用开源数据集―Kitti验证PENet模型效果；
  6. 使用PENet对自采数据集进行验证；  


Kitti数据集验证  
1.训练方式――随机crop  
为了统一kitti数据集与自采数据集分布情况，对kitti数据集稀疏深度图进行随机crop的处理，模拟自采数据集大范围稀疏情况。   
- 数据集制作  
crop的区域为矩形，取1/10kitti的训练集进行挖空，并用这些处理后的数据集进行训练。val得到的模型指标为：
  1. 原始的验证集：(mm)――该场景下的深度值大致0.5m-10m的范围    
  RMSE=1003.426  
  MAE=325.812  
  2. 随机crop的验证集：(mm)    
  RMSE=2578.309  
  MAE=975.044  

2.训练方式――语义crop  
为了验证PENet对局部crop的情况是否有效，随机进行矩形区域的crop策略太暴力，通过语义分割输出的mask，进行语义crop，挖掘PENet处理crop区域的能力。  
- 数据集制作  
crop的区域为kitti数据集中汽车所在的区域，取1/10kitti的数据集进行语义分割，然后再对kitti数据集相应的汽车区域进行crop。用这些处理后的数据集进行训练。val得到的模型指标为：
  1. 原始的验证集：(mm)――该场景下的深度值大致0.5m-10m的范围  
  RMSE=1003.426  
  MAE=325.812  
  2. 语义crop的验证集：(mm)  
  RMSE=1048.429  
  MAE=316.202 

3.训练方式――多种语义crop  
根据上一个实验得出的结论，证明PENet对语义crop是能work的，因此再通过添加多种语义信息验证其模型鲁棒性。  
- 数据集制作  
语义信息有汽车、道路和行人三种，crop的区域为三种类别所在的区域，训练集为原Kitti数据集的1/10。用这些处理后的数据集进行训练。val得到的模型指标为：
  1. 原始的验证集：(mm)――该场景下的深度值大致0.5m-10m的范围
  RMSE=1003.426
  MAE=325.812
  2. 多种语义crop的验证集：(mm)
  RMSE=1215.969
  MAE=461.742  

4.自采数据集验证  
验证低分辨率的tof点映射到realsense的高分辨率RGB摄像头上，构成的稀疏深度图进行深度补全的可行性。
- 数据集制作  
录包收集的数据集有5940条数据，每条数据包含一张rgb，一张realsense深度图和一张tof深度图。划分训练集数量：5757，验证集数量：183。  
验证集指标（mm）：――该场景下的深度值大致0.5m-4m的范围
    1. PENet第二阶段：(mm)   
    RMSE=5015.81         MAE=2800.44  
    2. PENet第三阶段：（mm）  
    RMSE=4601.67         MAE=2771.85  
- 成果  
对于语义深度补全的效果是可以使用的，但是需要提供场景下的物体语义标注信息，进行语义crop的标注训练，PENet才能很好的对深度信息缺失区域的深度信息进行还原。  
对于自采数据集的指标并不是特别好的情况下，分析得出可能的原因有： 
  1. 自采数据集太过稀疏，平均的有效点占整张图像不到5%；
  2. 数据集数量太少，训练指标和验证指标差距大；
  3. 数据集存在低质量的数据，比如rgb图像过于模糊，mapping的深度图有效点太少（小于3%）；  
目前该调研已经申请实验新型专利一项：《一种基于深度补全的TOF深度传感器优化系统及方法》

## 4. 人体宠物目标检测
- 背景  
割草机项目需要对草地上的活物进行检测，以便进行报警等中断处理。  
- 方案  
数据集：通过对coco数据集进行特定类别（person、cat、dog）的数据提取，加上公开的行人数据集和YouTube下载的草地低矮视角宠物视频，构成初始的数据集。    
模型：通过yoloxs进行训练  
- 指标  
per class AP:  
| class&nbsp;&nbsp;| AP&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;| class&nbsp;&nbsp;&nbsp;&nbsp;| AP &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | class   | AP&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|   
| dog&nbsp;&nbsp;&nbsp;| 51.293 | person  | 64.686 | cat&nbsp;&nbsp;&nbsp; | 71.924 |  
per class AR:  
| class&nbsp;&nbsp;| AR&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;| class&nbsp;&nbsp;&nbsp;&nbsp;| AR &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | class   | AR&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|   
| dog&nbsp;&nbsp;&nbsp;| 61.334 | person  | 74.862 | cat&nbsp;&nbsp;&nbsp; | 79.752 |   

- 结论  
在移动小车自采数据上测试，有很多误检的情况出现。经分析，原因可能训练集三个类别的比例的问题（person：dog：cat = 8：1：1），造成很多person类别的误检问题。  
解决方法：通过对这些误检的物体类别进行重标注成other类，再进行训练，可以大大改善误检的发生。  

## 5.日志分析看板

- 背景  
扫地机仿真系统每天都会定时跑仿真，生成运行日志。通过人工查验很消耗人力。因此，通过日志看板可以可视化日志的关键信息，比如运行时间，运行状态（失败or成果），房间清扫状态（导航、沿边、覆盖）上下基站状态等。

- 方案
通过正则匹配日志状态转移输出语句，通过扫地机状态转移闭环，分析日志逻辑，生成分析结果。最后，通过streamlit生成日志可视化看板页面

- 成果
能够在仿真后台实时生成日志分析报告